# Default system properties included when running spark-submit.

spark.app.name "Docker Test"

# use a mesos cluster, find master from zk
spark.master mesos://zk://master1:2181/mesos

# one mesos task per slave, multiple executors in there
spark.mesos.coarse true

# memory used by driver == the spark program/shell you're running
spark.driver.memory 1g

# snappy needs a C library I don't have in my image
spark.io.compression.codec lzf

# docker images with spark and a jvm
spark.mesos.executor.docker.image rasputnik/spark-1.6.1:v1
# SPARK_HOME in the image
spark.mesos.executor.home /spark-1.6.1-bin-hadoop2.6

# how many cores per executor?
spark.mesos.mesosExecutor.cores 0.2
spark.executor.memory 512M
