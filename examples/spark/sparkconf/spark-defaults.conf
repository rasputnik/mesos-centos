# Default system properties included when running spark-submit.

# one mesos task on each slave, jobs run in there
spark.mesos.coarse true

# use a mesos cluster, find master from zk
spark.master mesos://zk://master1:2181/mesos

# memory used by driver == the spark program/shell you're running
spark.driver.memory 2g
# docker images with spark and a jvm
spark.mesos.executor.docker.image mesosphere/spark:1.4.1-hdfs

# where is spark in the image? (found it via a 'docker run' to check)
# (without this the executor will use your shells values,
# which probably don't exist on the docker image)
spark.mesos.executor.home /opt/spark/dist
